{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = Path.cwd().parent.joinpath('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned vessel data\n",
    "\n",
    "vessels  = pd.read_excel(PATH.joinpath('processed', 'vessels_summary.xlsx'), sheet_name='vessel_check')\n",
    "\n",
    "# Filter for vessels that have a final check in/out\n",
    "selection = vessels[vessels['final check in/out']==True].copy()\n",
    "selection[['start_date', 'end_date_equasis', 'end_date_checked']] = selection[['start_date', 'end_date_equasis', 'end_date_checked']].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import latest KSE data\n",
    "\n",
    "kse1 = pd.read_excel(PATH.joinpath('processed', 'kse_shadowfleetv2.xlsx'), skiprows=1)\n",
    "kse1.imo = kse1.imo.astype('int64')\n",
    "kse1['tanker_type'] = 'oil tanker'\n",
    "kse2 = pd.read_excel(PATH.joinpath('processed', 'kse_shadowfleetv2.xlsx'), sheet_name='Oli product.All', skiprows=4)\n",
    "kse2['tanker_type'] = 'oil product tanker'\n",
    "kse2.columns = kse1.columns\n",
    "\n",
    "\n",
    "kse = pd.concat([kse1, kse2])\n",
    "kse.dropna(subset=['imo'], inplace=True)\n",
    "kse.imo = kse.imo.astype('int64')\n",
    "kse.build = kse.build.astype('int64')\n",
    "len(kse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kse.to_csv(PATH.joinpath('processed', 'kse_shadowfleetv2.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get company flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get imos from checked vessels\n",
    "\n",
    "imos = selection.imo.unique()\n",
    "\n",
    "# Import company data\n",
    "\n",
    "companies = pd.read_excel(PATH.joinpath('processed', 'vessels_summary.xlsx'), sheet_name='companies')\n",
    "\n",
    "# Filter relevant companies\n",
    "companies = companies[(companies.imo.isin(imos)) & (companies.role=='Registered owner') & (companies.start_date > '2022-03-01')].copy()\n",
    "\n",
    "companies.start_date = pd.to_datetime(companies.start_date)\n",
    "\n",
    "# Merge with checked data data\n",
    "\n",
    "df = pd.merge(companies, \n",
    "            selection[['imo', 'jurisdiction', 'ubo_jurisdiction', 'end_date_checked']],\n",
    "            on='imo',\n",
    "            how='left')\n",
    "\n",
    "# Create columns with next jurisdiction\n",
    "\n",
    "# Merge the dataframe with itself to get the next jurisdiction and next ubo_jurisdiction\n",
    "df = pd.merge(df, df[['imo', 'start_date', 'jurisdiction', 'ubo_jurisdiction']], \n",
    "              left_on=['imo', 'end_date'], \n",
    "              right_on=['imo', 'start_date'], \n",
    "              suffixes=('', '_next'), \n",
    "              how='left')\n",
    "\n",
    "# Fill the next_jurisdiction and next_ubo_jurisdiction with the country if there is no end_date match\n",
    "df['next_jurisdiction'] = df['jurisdiction_next'].fillna(df['country'])\n",
    "df['next_ubo_jurisdiction'] = df['ubo_jurisdiction_next'].fillna(df['country'])\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "df.drop(columns=['start_date_next', 'jurisdiction_next', 'ubo_jurisdiction_next'], inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ubo_jurisdiction', 'next_ubo_jurisdiction']].value_counts().reset_index().to_csv(PATH.joinpath('processed', 'ubo_jurisdiction_changes.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare vessels with lloyds list data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lloyds = pd.read_csv(PATH.joinpath('processed', 'lloydslist_shadowfleet.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(lloyds.IMO).difference(set(vessels.imo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kse.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kse[~kse.imo.isin(list(set(lloyds.IMO)))].groupby('build').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "cols = [col for col in kse1.columns if '202' in col]\n",
    "for i, row in kse1.iterrows():\n",
    "    for col in cols[3:]:\n",
    "        if pd.isnull(row[col]):\n",
    "            continue    \n",
    "        else:\n",
    "            record = {'imo': row.imo,\n",
    "                      'start_date': f'01-{col[:-5]}-{col[-4:]}'}\n",
    "            rows.append(record)\n",
    "\n",
    "uninsured = pd.DataFrame(rows)\n",
    "uninsured.start_date = pd.to_datetime(uninsured.start_date, \n",
    "                                      format='%d-%m-%Y', \n",
    "                                      dayfirst=True)\n",
    "\n",
    "uninsured['end_date'] = pd.to_datetime(uninsured['start_date'], \n",
    "                                       format=\"%Y%m\") + pd.tseries.offsets.MonthEnd(0)\n",
    "\n",
    "# Create date ranges\n",
    "uninsured = uninsured.groupby('imo').agg({'start_date': 'min', \n",
    "                                          'end_date': 'max'}).reset_index()\n",
    "\n",
    "# And add sanction date to the uninsured dataframe\n",
    "\n",
    "uninsured = pd.merge(uninsured, \n",
    "                     kse1[['imo', 'earliest_sanction_date', 'total_mln_barrels']], \n",
    "                     on='imo', \n",
    "                     how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'imo'\n",
    "merged_df = pd.merge(selection[['imo', 'end_date_equasis']], uninsured, on='imo', how='left')\n",
    "\n",
    "# Filter the merged dataframe\n",
    "filtered_selection = merged_df[merged_df['start_date'] > merged_df['end_date_equasis']]\n",
    "\n",
    "# Drop the columns from the uninsured dataframe to get the original structure of selection\n",
    "#filtered_selection = filtered_selection[selection.columns]\n",
    "\n",
    "# Display the filtered dataframe\n",
    "filtered_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
