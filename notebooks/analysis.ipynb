{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "PATH = Path.cwd().parent.joinpath('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "The goal of this notebook is to perform exploratory data analysis on the shadowfleet data and create a model for a graph database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "First we need to know if we have all necessary data and if not, what data we are missing. Our starting point is the shadowfleet data provided by the Kiev School of Economics Institute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kse = pd.read_csv(PATH.joinpath('processed', 'kse_shadowfleet.csv'),\n",
    "                  parse_dates=['earliest_sanction_date'],\n",
    "                  date_format=lambda x: pd.to_datetime(x, \n",
    "                                                       errors='coerce', \n",
    "                                                       format='%d-%m-%Y', \n",
    "                                                       dayfirst=True))\n",
    "\n",
    "# create a set of imos\n",
    "imos = set(kse.imo)\n",
    "\n",
    "# Some vessels have multiple entries in the dataseet (because they carry multiple products)\n",
    "# We will drop the duplicates\n",
    "\n",
    "kse_dedup = kse.drop_duplicates(subset='imo')\n",
    "\n",
    "print(f'''The KSE dataset contains {len(imos)} unique vessels\n",
    "of which {kse[kse.earliest_sanction_date.notna()].imo.nunique()} are sanctioned.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's dive into the sanctions: when were they sanctioned?\n",
    "\n",
    "sanctions = kse_dedup.groupby('earliest_sanction_date').imo.count().reset_index()\n",
    "\n",
    "sanctions['earliest_sanction_date'] = pd.to_datetime(sanctions['earliest_sanction_date'], \n",
    "                                                     errors='coerce', \n",
    "                                                     format='%d-%m-%Y', dayfirst=True)\n",
    "\n",
    "sanctions.earliest_sanction_date = pd.to_datetime(sanctions.earliest_sanction_date)\n",
    "sanctions.sort_values('earliest_sanction_date', inplace=True)\n",
    "sanctions.set_index('earliest_sanction_date', inplace=True, drop=True)\n",
    "\n",
    "# Sanction dates\n",
    "\n",
    "px.bar(sanctions,\n",
    "       title='Sanction Dates',\n",
    "       labels={'earliest_sanction_date':'Sanction Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the Age of the shadowfleet?\n",
    "\n",
    "px.histogram(kse_dedup, x='buildyear',\n",
    "             title='Age of the Shadowfleet',\n",
    "             labels={'buildyear':'Build Year'},\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the flag distribution? (N.B. the current flag is the flag as of 6th August 2024)\n",
    "\n",
    "px.bar(kse_dedup.groupby('current_flag_06082024').imo.count()).\\\n",
    "       update_xaxes(categoryorder='total descending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When dit the vessels enter the shadowfleet? (use our uninsured data)\n",
    "# The first date should be discarded as it is the date of the first entry in the dataset, but the start of measurements\n",
    "\n",
    "uninsured = pd.read_csv(PATH.joinpath('processed', 'uninsured.csv'),\n",
    "                        parse_dates=['start_date', 'end_date', 'earliest_sanction_date'],\n",
    "                        date_format='%Y-%m-%d')\n",
    "\n",
    "px.bar(uninsured.groupby('start_date').imo.count(),\n",
    "       title='Entry Dates of the Shadowfleet',\n",
    "       labels={'start_date':'Entry Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And what are the end dates? The last date (July 2024) should be discarded because it is not a real end date, but the end of measurements.\n",
    "\n",
    "px.bar(uninsured.groupby('end_date').imo.count(),\n",
    "       title='Exit Dates of the Shadowfleet',\n",
    "       labels={'start_date':'Exit Date'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company histories and details\n",
    "\n",
    "The equasis data consists of lists of companies owning or managing a vessel through time. That data is based on the IMO registry and could be very useful in finding relevant changes in vessel ownership. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = pd.read_csv(PATH.joinpath('processed', 'owners_companies.csv'))\n",
    "companies[['start_date', 'end_date']] = companies[['start_date', 'end_date']].apply(pd.to_datetime)\n",
    "len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any vessels in the shadowfleet that we don't have company information for?\n",
    "\n",
    "print(f'There is {len(set(kse.imo).difference(set(companies.imo)))} imos not in the other dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many UNKNOWN companies are in this dataset?\n",
    "\n",
    "companies[companies.company == 'UNKNOWN'].company.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be relevant. Let's see these missing values over time. If they are old, than its just an administrative issue. If the missing companies are more recent, then it would be interesting to know why these companies aren't known. The unknown companies are all ISM Managers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = companies[companies.company == 'UNKNOWN'].copy()\n",
    "unknown.start_date = pd.to_datetime(unknown.start_date, errors='coerce', format='%Y-%m-%d', dayfirst=True).dt.year\n",
    "px.histogram(unknown, x='start_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of roles are unknown?\n",
    "\n",
    "unknown.role.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What companies had many ownership changes after the start of the Ukraine war?\n",
    "\n",
    "companies.query('role == \"Registered owner\" & start_date > \"01-01-2022\"')\\\n",
    "         .groupby('imo')\\\n",
    "         .agg(ownership_changes=('company', 'nunique'))\\\n",
    "         .sort_values('ownership_changes', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the vessel with the most ownership changes after the Ukraine war\n",
    "\n",
    "pd.merge(companies.query('imo == 9302126 & role == \"Registered owner\"'),\n",
    "         kse[['imo', 'vessel_name']],\n",
    "         on='imo',\n",
    "         how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When did ownership change?\n",
    "\n",
    "px.bar(companies.groupby([pd.Grouper(key='end_date', freq='ME'), 'role'])\\\n",
    "                .agg(count=('role', 'count'))\\\n",
    "                .reset_index()\\\n",
    "                .set_index('end_date', drop=True).query('index > \"01-01-2014\"'),\n",
    "       color='role',\n",
    "       title='Ownership Changes Over Time',\n",
    "       labels={'end_date':'End Date',\n",
    "               'value': 'Number of Ownership Changes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_details = pd.read_csv(PATH.joinpath('processed', 'owners_companies_details.csv'))\n",
    "com_details[['last_update', 'since']] = com_details[['last_update', 'since']].apply(pd.to_datetime)\n",
    "com_details[['imo', 'company_imo', 'year_of_build']] = com_details[['imo', 'company_imo', 'year_of_build']].astype(int)\n",
    "com_details.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events\n",
    "\n",
    "Analyse port visits, loitering, AIS gaps and activity in known ship-to-ship transfer zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports = pd.read_parquet(PATH.joinpath('processed', 'ports.parquet'))\n",
    "loitering = pd.read_parquet(PATH.joinpath('processed', 'loitering.parquet'))\n",
    "ais = pd.read_parquet(PATH.joinpath('processed', 'ais.parquet'))\n",
    "sts = pd.read_parquet(PATH.joinpath('processed', 'sts_tracks.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Port visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean ports\n",
    "\n",
    "ports[['start', 'end']] = ports[['start', 'end']].apply(lambda x: pd.to_datetime(x).dt.date)\n",
    "\n",
    "# See port visits over time\n",
    "\n",
    "ports[ports.port_visit_startAnchorage_id.str.contains('tur-')].port_visit_startAnchorage_name.value_counts().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports['port_name'] = ports.groupby(['port_visit_startAnchorage_id'])['port_visit_startAnchorage_name'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports[ports.start > pd.to_datetime('2022-01-01').date()].to_csv(PATH.joinpath('processed', 'port_visits_2022.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter 3 iso country code and port name\n",
    "\n",
    "COUNTRY = 'tur'\n",
    "PORT = 'AMBARLI'\n",
    "\n",
    "px.bar(ports[(ports.port_visit_startAnchorage_id.str.contains(f'{COUNTRY}-')) \\\n",
    "             & (ports.port_visit_startAnchorage_name==PORT)].groupby(pd.Grouper(key='start', freq='ME')).agg(visits=('ssvid', 'count')),\n",
    "             title=f'Port visits from shadowfleet vessels to {PORT} by month',\n",
    "             labels={'visits': 'Number of visits',\n",
    "                     'start': 'Time'},)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loitering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loitering[['start', 'end']] = loitering[['start', 'end']].apply(pd.to_datetime)\n",
    "loitering = loitering[loitering.start >= '2022-01-01'].copy()\n",
    "loitering[['start', 'end']] = loitering[['start', 'end']].apply(lambda x: x.dt.date)\n",
    "len(loitering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "loitering.to_csv(PATH.joinpath('processed', 'loitering_2022.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loitering.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ais['geometry'] = ais.apply(lambda x: LineString([(x['gap_offposition_lon'], x['gap_offposition_lat']) , (x['gap_onposition_lon'], x['gap_onposition_lat'])]), axis = 1)\n",
    "ais = gpd.GeoDataFrame(ais, geometry='geometry', crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais[['geometry', 'name']].explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ship-to-ship transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean STS\n",
    "\n",
    "sts.drop('seg_id', axis=1, inplace=True)\n",
    "sts.timestamp = pd.to_datetime(sts.timestamp)\n",
    "sts.query('timestamp > \"2022-01-01\"', inplace=True)\n",
    "sts.sort_values('timestamp', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts['week'] = sts.timestamp.dt.to_period('W').apply(lambda x: x.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.groupby(['name', 'week']).agg(count=('name', 'count')).reset_index().sort_values('count', ascending=False).name.value_counts()[140:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts = gpd.GeoDataFrame(sts, geometry=gpd.points_from_xy(x=sts.lon, y=sts.lat), crs='EPSG:4326')\n",
    "sts.week = sts.week.astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_locations = gpd.read_file(PATH.joinpath('geo', 'sts_locations.geojson'))\n",
    "sts_locations.set_geometry('geometry', crs='EPSG:4326', inplace=True)\n",
    "sts = gpd.sjoin(sts, sts_locations, how='left', predicate='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.drop('index_right', axis=1, inplace=True)\n",
    "sts.rename(columns={'Name':'sts_location'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.groupby('name').agg(count=('sts_location', 'nunique')).sort_values('count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.query('name==\"AIDA\"')[['geometry', 'week']].explore(column='week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with helennic shipping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hel = pd.read_csv(PATH.joinpath('processed', 'hellenic_shipping.csv'), sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv(PATH.joinpath('processed', 'owners_names.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(kse.vessel_name.str.upper().str.replace(' ', '')).intersection(hel.NAME.str.replace(' ', '').str.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
